#!/usr/bin/env python3
"""
GPU Installation Diagnostic Script
Check why models cannot use GPU
"""

import sys

def check_pytorch_gpu():
    """Check PyTorch GPU support"""
    print("üîç PYTORCH GPU CHECK")
    print("=" * 50)
    
    try:
        import torch
        print(f"PyTorch version: {torch.__version__}")
        print(f"CUDA available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"CUDA version: {torch.version.cuda}")
            print(f"GPU count: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
            return True
        else:
            print("‚ùå PyTorch CUDA not available")
            print("üí° Install with: pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
            return False
            
    except Exception as e:
        print(f"‚ùå PyTorch check failed: {e}")
        return False

def check_paddlepaddle_gpu():
    """Check PaddlePaddle GPU support"""
    print("\nüîç PADDLEPADDLE GPU CHECK")
    print("=" * 50)
    
    try:
        import paddle
        print(f"PaddlePaddle version: {paddle.__version__}")
        print(f"Compiled with CUDA: {paddle.device.is_compiled_with_cuda()}")
        
        if paddle.device.is_compiled_with_cuda():
            print(f"GPU count: {paddle.device.cuda.device_count()}")
            print("‚úÖ PaddlePaddle has GPU support")
            return True
        else:
            print("‚ùå PaddlePaddle CPU version installed")
            print("üí° Install GPU version with:")
            print("   pip uninstall paddlepaddle")
            print("   pip install paddlepaddle-gpu")
            return False
            
    except Exception as e:
        print(f"‚ùå PaddlePaddle check failed: {e}")
        return False

def check_ultralytics_gpu():
    """Check Ultralytics GPU support"""
    print("\nüîç ULTRALYTICS GPU CHECK")
    print("=" * 50)
    
    try:
        from ultralytics import YOLO
        import torch
        
        print("Ultralytics installed ‚úÖ")
        print(f"PyTorch backend CUDA: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print("‚úÖ Ultralytics can use GPU via PyTorch")
            return True
        else:
            print("‚ùå Ultralytics will use CPU only")
            return False
            
    except Exception as e:
        print(f"‚ùå Ultralytics check failed: {e}")
        return False

def check_transformers_gpu():
    """Check Transformers GPU support"""
    print("\nüîç TRANSFORMERS GPU CHECK")
    print("=" * 50)
    
    try:
        import transformers
        import torch
        
        print(f"Transformers version: {transformers.__version__}")
        print(f"PyTorch backend CUDA: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print("‚úÖ Transformers can use GPU via PyTorch")
            return True
        else:
            print("‚ùå Transformers will use CPU only")
            return False
            
    except Exception as e:
        print(f"‚ùå Transformers check failed: {e}")
        return False

def get_installation_commands():
    """Provide installation commands for GPU support"""
    print("\nüí° GPU INSTALLATION GUIDE")
    print("=" * 50)
    
    print("To enable GPU support for all models:")
    print()
    print("1. üî• PyTorch GPU (for YOLO, YOLIC, SmolVLM):")
    print("   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
    print()
    print("2. üöÄ PaddlePaddle GPU (for PaddleOCR):")
    print("   pip uninstall paddlepaddle")
    print("   pip install paddlepaddle-gpu")
    print()
    print("3. üì¶ Or install both together:")
    print("   pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118")
    print("   pip uninstall paddlepaddle")
    print("   pip install paddlepaddle-gpu")
    print()
    print("Note: Make sure you have CUDA 11.8+ installed on your system")
    print("Check CUDA: nvidia-smi")

def main():
    """Run all GPU checks"""
    print("üöÄ GPU INSTALLATION DIAGNOSTIC")
    print("=" * 60)
    
    results = {
        "PyTorch": check_pytorch_gpu(),
        "PaddlePaddle": check_paddlepaddle_gpu(), 
        "Ultralytics": check_ultralytics_gpu(),
        "Transformers": check_transformers_gpu()
    }
    
    print("\nüìä SUMMARY")
    print("=" * 50)
    
    for framework, has_gpu in results.items():
        status = "üü¢ GPU Ready" if has_gpu else "üî¥ CPU Only"
        print(f"{framework:12} : {status}")
    
    gpu_ready = sum(results.values())
    total = len(results)
    
    print(f"\nGPU-ready frameworks: {gpu_ready}/{total}")
    
    if gpu_ready == 0:
        print("\n‚ùå No frameworks have GPU support!")
        print("This means all models will run on CPU (much slower)")
    elif gpu_ready < total:
        print(f"\n‚ö†Ô∏è Only {gpu_ready} frameworks have GPU support")
        print("Some models will be slower on CPU")
    else:
        print("\nüéâ All frameworks have GPU support!")
        print("Models will run at optimal speed")
    
    if gpu_ready < total:
        get_installation_commands()
    
    return gpu_ready > 0

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
